// Copyright (c) 2025 John Doe
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//	http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
package aillm

import (
	"bytes"
	"context"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"os"
	"time"

	"github.com/gabriel-vasile/mimetype"
)

// Structures needed for the request
type ChatCompletionRequest struct {
	Model            string            `json:"model"`
	Messages         []Message         `json:"messages"`
	Temperature      float64           `json:"temperature"`
	MaxTokens        int               `json:"max_completion_tokens"`
	TopP             float64           `json:"top_p"`
	FrequencyPenalty float64           `json:"frequency_penalty"`
	PresencePenalty  float64           `json:"presence_penalty"`
	ResponseFormat   map[string]string `json:"response_format"`
}

type Message struct {
	Role    string      `json:"role"`
	Content interface{} `json:"content"`
}

// Structures needed for the response
type ChatCompletionResponse struct {
	ID      string   `json:"id"`
	Object  string   `json:"object"`
	Created int64    `json:"created"`
	Model   string   `json:"model"`
	Choices []Choice `json:"choices"`
	Usage   Usage    `json:"usage"`
}

type Choice struct {
	Index        int          `json:"index"`
	Message      ReplyMessage `json:"message"`
	FinishReason string       `json:"finish_reason"`
}

type ReplyMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

// DescribeImage sends an image along with a text query to an AI vision model for description.
//
// This function constructs a JSON payload containing the provided image (Base64-encoded) and query,
// then sends an HTTP POST request to the AI model endpoint. The API response is processed to extract
// the textual description of the image.
//
// Parameters:
//   - encodedImage: A string containing the Base64-encoded image data.
//   - query: A text prompt to know how to deal with the image (e.g., "Describe this image.").
//   - options: Variadic LLMCallOption parameters for additional configuration (if applicable).
//
// Returns:
//   - string: The textual description generated by the AI model.
//   - error: An error if the request fails or the response is invalid.
//
// Example Usage:
//
//	description, err := llm.DescribeImage(encodedImage, "Describe this image.")
//	if err != nil {
//	    log.Fatalf("Error: %v", err)
//	}
//	fmt.Println("Image Description:", description)
//
// Notes:
//   - The function extracts the AI model and API details from `llm.VisionClient.GetConfig()`.
//   - It expects a valid API token to be set in `llm.VisionClient.GetConfig().APIToken`.
//   - The function handles HTTP request creation, response validation, and JSON parsing.
//   - If the API response structure changes, parsing logic might require adjustments.

func (llm *LLMContainer) DescribeImage(encodedImage, query string, options ...LLMCallOption) (ChatCompletionResponse, error) {
	o := LLMCallOptions{}
	for _, opt := range options {
		opt(&o)
	}

	if o.MaxTokens == 0 {
		o.MaxTokens = 2048
	}
	config := llm.VisionClient.GetConfig()
	apiKey := config.APIToken
	url := config.Apiurl + "chat/completions"
	response := ChatCompletionResponse{}
	request := ChatCompletionRequest{
		Model: config.AiModel,
		Messages: []Message{
			{
				Role: "user",
				Content: []map[string]interface{}{
					{
						"type": "image_url",
						"image_url": map[string]string{
							"url":  encodedImage,
						},
					},
					{
						"type": "text",
						"text": query,
					},
				},
			},
		},
		Temperature:      llm.Temperature,
		MaxTokens:        o.MaxTokens,
		TopP:             llm.TopP,
		FrequencyPenalty: 0.0,
		PresencePenalty:  0.0,
		ResponseFormat:   map[string]string{"type": "text"},
	}

	// Convert request to JSON
	requestBody, err := json.Marshal(request)
	if err != nil {
		return response, fmt.Errorf("Error converting request to JSON: %v\n", err)
	}

	// Create context with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	// Create HTTP request
	req, err := http.NewRequestWithContext(ctx, "POST", url, bytes.NewBuffer(requestBody))
	if err != nil {
		return response, fmt.Errorf("Error creating HTTP request: %v\n", err)
	}

	// Set HTTP headers
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+apiKey)

	// Send request
	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		return response, fmt.Errorf("Error sending request: %v\n", err)
	}
	defer resp.Body.Close()

	// Read response
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return response, fmt.Errorf("Error reading response: %v\n", err)
	}

	// Check status code
	if resp.StatusCode != http.StatusOK {
		return response, fmt.Errorf("API Error: Status code %d\nResponse: %s\n", resp.StatusCode, string(body))
	}

	// Convert JSON response to Go structure
	if err := json.Unmarshal(body, &response); err != nil {
		return response, fmt.Errorf("Error parsing JSON response: %v\n", err)
	}

	// Display complete response
	return response, nil
}

// DescribeImageFromFile reads an image file, encodes it to Base64, and sends it along with a text query
// to an AI vision model for description.
//
// This function reads an image file from the specified path, converts it to a Base64-encoded string,
// and calls the `DescribeImage` function to obtain a textual description of the image.
//
// Parameters:
//   - imagePath: The file path of the image to be processed.
//   - query: A text query to describe the image (e.g., "Describe this image.").
//   - options: Variadic LLMCallOption parameters for additional configuration (if applicable).
//
// Returns:
//   - string: The textual description generated by the AI model.
//   - error: An error if the file cannot be read, encoding fails, or the AI request encounters an issue.
//
// Example Usage:
//
//	description, err := llm.DescribeImageFromFile("sample.jpg", "Describe this image.")
//	if err != nil {
//	    log.Fatalf("Error: %v", err)
//	}
//	fmt.Println("Image Description:", description)
//
// Notes:
//   - The function reads the image as a binary file using `os.ReadFile()`.
//   - It converts the image to a Base64-encoded string before calling `DescribeImage()`.
//   - Requires a valid API token and properly configured `llm.VisionClient` settings.
//   - If the image file is too large, encoding may consume significant memory.
func (llm *LLMContainer) DescribeImageFromFile(imagePath, query string, options ...LLMCallOption) (ChatCompletionResponse, error) {
	// reading image file
	imageData, err := os.ReadFile(imagePath)
	if err != nil {
		return ChatCompletionResponse{}, fmt.Errorf("error reading file: %v", err)
	}

	detectedMimeType, mimedetectionErr := mimetype.DetectFile(imagePath)
	// checking for errors
	if mimedetectionErr != nil {
		return ChatCompletionResponse{}, fmt.Errorf("error detecting mime type: %v", mimedetectionErr)
	}
	// converting image to base64 string
	encodedImage := fmt.Sprintf("data:"+detectedMimeType.String()+";base64,%s", base64.StdEncoding.EncodeToString(imageData))
	return llm.DescribeImage(encodedImage, query, options...)
}
